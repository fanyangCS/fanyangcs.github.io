---
---

@inproceedings{FractalTensorSosp24,
  abbr         = {SOSP},
  bibtex_show  = {true},
  author       = {Siran Liu and Chengxiang Qi and Ying Cao and Chao Yang and Weifang Hu and Xuanhua Shi and Fan Yang and Mao Yang },
  title        = {Uncovering Nested Data Parallelism and Data Reuse in DNN Computation with FractalTensor},
  booktitle    = {{SOSP}},
  selected     = {true},
  year         = {2024}
}

@article{qi2024mutualreasoningmakessmaller,
      abbr={ArXiv},
      bibtex_show={true},      
      title={Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers}, 
      author={Zhenting Qi and Mingyuan Ma and Jiahang Xu and Li Lyna Zhang and Fan Yang and Mao Yang},
      year={2024}, 
      journal={ArXiv},      
      html={https://arxiv.org/abs/2408.06195},
      code={https://github.com/zhentingqi/rStar},
      award_name={Hugging Face Daily Papers},
      award={Selected as Hugging Face [daily papers](https://huggingface.co/papers?date=2024-08-13) (2024-08-13).}
}

@inproceedings{ding2024longrope,
  abbr={ICML},
  bibtex_show={true},
  author = {Ding, Yiran and Zhang, Li Lyna and Zhang, Chengruidong and Xu, Yuanyuan and Shang, Ning and Xu, Jiahang and Yang, Fan and Yang, Mao},
  title = {LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens},
  booktitle = {ICML 2024},
  year = {2024},
  code={https://github.com/microsoft/LongRoPE},
  poster={https://icml.cc/media/icml-2024/Slides/34166.pdf},
  award={Selected as Hugging Face daily papers: [#1 paper of the day](https://huggingface.co/papers?date=2024-02-22) (2024-02-22).},
  award_name={Hugging Face Daily Papers},
  html = {https://www.microsoft.com/en-us/research/publication/longrope-extending-llm-context-window-beyond-2-million-tokens/}
}

@article{Abdin2024Phi3TR,
  abbr={ArXiv},
  bibtex_show={true},
  title={Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone},
  author={Marah Abdin and Sam Ade Jacobs and Ammar Ahmad Awan and Jyoti Aneja and Ahmed Awadallah and Hany Hassan Awadalla and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Harkirat Singh Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and S{\'e}bastien Bubeck and Martin Cai and Caio C'esar Teodoro Mendes and Weizhu Chen and Vishrav Chaudhary and Parul Chopra and Allison Del Giorno and Gustavo de Rosa and Matthew Dixon and Ronen Eldan and Dan Iter and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J. Hewett and Jamie Huynh and Mojan Javaheripi and Xin Jin and Piero Kauffmann and Nikos Karampatziakis and Dongwoo Kim and Mahoud Khademi and Lev Kurilenko and James R. Lee and Yin Tat Lee and Yuanzhi Li and Chen Liang and Weishung Liu and Eric Lin and Zeqi Lin and Piyush Madan and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Corby Rosset and Sambudha Roy and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Xianmin Song and Olatunji Ruwase and Xin Wang and Rachel Ward and Guanhua Wang and Philipp Witte and Michael Wyatt and Can Xu and Jiahang Xu and Sonali Yadav and Fan Yang and Ziyi Yang and Donghan Yu and Cheng-Yuan Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yunan Zhang and Xiren Zhou},
  journal={ArXiv},
  code={https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3},
  additional_info={. (Applying [LongRoPE](https://www.microsoft.com/en-us/research/publication/longrope-extending-llm-context-window-beyond-2-million-tokens/) to [Phi-3](https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/))},
  google_scholar_id={tkaPQYYpVKoC},
  year={2024}, 
  selected={true},
  html={https://arxiv.org/abs/2404.14219}
}

@inproceedings{nnscaler24,
  abbr         = {OSDI},  
  bibtex_show  = {true},
  author       = {Lin, Zhiqi and Miao, Youshan and Zhang, Quanlu and Yang, Fan and Zhu, Yi and Li, Cheng and Maleki, Saeed and Cao, Xu and Shang, Ning and Yang, Yilei and Xu, Weijiang and Yang, Mao and Zhang, Lintao and Zhou, Lidong},
  title        = {nnScaler: Constraint-Guided Parallelization Plan Generation for Deep Learning Training},
  booktitle    = {18th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  html         = {https://www.microsoft.com/en-us/research/publication/nnscaler-constraint-guided-parallelization-plan-generation-for-deep-learning-training/},
  slides       = {https://www.microsoft.com/en-us/research/uploads/prodnew/2024/07/nnscaler_osdi24.pdf},
  code         = {https://github.com/microsoft/nnscaler},
  selected     = {true},
  year         = {2024}
}

@inproceedings{parrot24,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Lin, Chaofan and Han, Zhenhua and Zhang, Chengruidong and Yang, Yuqing and Yang, Fan and Chen, Chen and Qiu, Lili},
  title        = {Parrot: Efficient Serving of LLM-based Applications with Semantic Variable},
  booktitle    = {18th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  slides       = {https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/Parrot-OSDI24.pdf},
  code         = {https://github.com/microsoft/ParrotServe},
  html         = {https://www.microsoft.com/en-us/research/publication/parrot-efficient-serving-of-llm-based-applications-with-semantic-variable/},
  selected     = {true},
  year         = {2024}
}

@inproceedings{ladder24,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Wang, Lei and Ma, Lingxiao and Cao, Shijie and Zhang, Quanlu and Xue, Jilong and Shi, Yining and Zheng, Ningxin and Miao, Ziming and Yang, Fan and Cao, Ting and Yang, Yuqing and Yang, Mao},
  title        = {Ladder: Enabling Efficient Low-Precision Deep Learning Computing through Hardware-aware Tensor Transformation},
  booktitle    = {18th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  code         = {https://github.com/microsoft/BitBLAS},
  html         = {https://www.microsoft.com/en-us/research/publication/ladder-enabling-efficient-low-precision-deep-learning-computing-through-hardware-aware-tensor-transformation/},
  selected     = {true},
  year         = {2024}
}

@inproceedings{10.1145/3617232.3624864,
  abbr         = {ASPLOS},
  bibtex_show  = {true},
  author       = {Guan, Yue and Qiu, Yuxian and Leng, Jingwen and Yang, Fan and Yu, Shuo and Liu, Yunxin and Feng, Yu and Zhu, Yuhao and Zhou, Lidong and Liang, Yun and Zhang, Chen and Li, Chao and Guo, Minyi},
  title        = {Amanda: Unified Instrumentation Framework for Deep Neural Networks},  
  booktitle    = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS'24},
  html         = {https://dl.acm.org/doi/10.1145/3617232.3624864},
  year         = {2024}
}


@inproceedings{conf/eurosys/LMLSMYBW00Y24,
  abbr         = {EuroSys},
  bibtex_show  = {true},
  author       = {Guodong Liu and Youshan Miao and Zhiqi Lin and Xiaoxiang Shi and Saeed Maleki and Fan Yang and Yungang Bao and Sa Wang},
  title        = {Aceso: Efficient Parallel DNN Training through Iterative Bottleneck Alleviation},
  booktitle    = {Proceedings of the Nineteenth European Conference on Computer Systems, {EuroSys}},
  html         = {https://dl.acm.org/doi/10.1145/3627703.3629554},
  year         = {2024}
}

@inproceedings{conf/hpca/LMXLOMF00Y24,
  abbr         = {HPCA},
  bibtex_show  = {true},
  author       = {Zhiqi Lin and Youshan Miao and Guanbin Xu and Cheng Li and Olli Saarikivi and Saeed Maleki and Fan Yang },
  title        = {Tessel: Boosting Distributed DNN Execution with Flexible Schedule Search},
  booktitle    = {30th International Symposium on High-Performance Computer Architecture, {HPCA}},
  html         = {https://ieeexplore.ieee.org/document/10476399},
  year         = {2024}
}

@inproceedings{DBLP:conf/osdi/ZhangXCSXCCH00Y23,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Qianxi Zhang and
                  Shuotao Xu and
                  Qi Chen and
                  Guoxin Sui and
                  Jiadong Xie and
                  Zhizhen Cai and
                  Yaoqi Chen and
                  Yinxuan He and
                  Yuqing Yang and
                  Fan Yang and
                  Mao Yang and
                  Lidong Zhou},
  title        = {{VBASE:} Unifying Online Vector Similarity Search and Relational Queries via Relaxed Monotonicity},
  booktitle    = {17th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  html         = {https://www.usenix.org/conference/osdi23/presentation/zhang-qianxi},
  year         = {2023}
}

@inproceedings{DBLP:conf/osdi/ZhangMXSM0Z0Y23,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Chen Zhang and
                  Lingxiao Ma and
                  Jilong Xue and
                  Yining Shi and
                  Ziming Miao and
                  Fan Yang and
                  Jidong Zhai and
                  Zhi Yang and
                  Mao Yang},
  title        = {Cocktailer: Analyzing and Optimizing Dynamic Control Flow in Deep Learning},
  html         = {https://www.microsoft.com/en-us/research/publication/cocktailer-analyzing-and-optimizing-dynamic-control-flow-in-deep-learning/},
  booktitle    = {17th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  year         = {2023}
}

@inproceedings{DBLP:conf/osdi/00010XMXMG0Z23,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Yining Shi and
                  Zhi Yang and
                  Jilong Xue and
                  Lingxiao Ma and
                  Yuqing Xia and
                  Ziming Miao and
                  Yuxiao Guo and
                  Fan Yang and
                  Lidong Zhou},
  title        = {Welder: Scheduling Deep Learning Memory Access via Tile-graph},
  booktitle    = {17th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  html         = {https://www.microsoft.com/en-us/research/publication/welder-scheduling-deep-learning-memory-access-via-tile-graph/},
  year         = {2023}
}

@inproceedings{DBLP:conf/osdi/CuiHOWZM00XQZ0T23,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Weihao Cui and
                  Zhenhua Han and
                  Lingji Ouyang and
                  Yichuan Wang and
                  Ningxin Zheng and
                  Lingxiao Ma and
                  Yuqing Yang and
                  Fan Yang and
                  Jilong Xue and
                  Lili Qiu and
                  Lidong Zhou and
                  Quan Chen and
                  Haisheng Tan and
                  Minyi Guo},
  title        = {Optimizing Dynamic Neural Networks with Brainstorm},
  booktitle    = {17th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  html         = {https://www.microsoft.com/en-us/research/publication/optimizing-dynamic-neural-networks-with-brainstorm/},
  year         = {2023}
}

@inproceedings{DBLP:conf/sosp/ZhengJZHM0YZQYZ23,
  abbr         = {SOSP},
  bibtex_show  = {true},
  author       = {Ningxin Zheng and
                  Huiqiang Jiang and
                  Quanlu Zhang and
                  Zhenhua Han and
                  Lingxiao Ma and
                  Yuqing Yang and
                  Fan Yang and
                  Chengruidong Zhang and
                  Lili Qiu and
                  Mao Yang and
                  Lidong Zhou},
  title        = {{PIT:} Optimization of Dynamic Sparse Deep Learning Models via Permutation Invariant Transformation},
  html         = {https://www.microsoft.com/en-us/research/publication/pit-optimization-of-dynamic-sparse-deep-learning-models-via-permutation-invariant-transformation/},
  booktitle    = {Proceedings of the 29th Symposium on Operating Systems Principles, {SOSP}},
  year         = {2023}}


@inproceedings{DBLP:conf/sosp/XuLLXCZLYYYCY23,
  abbr         = {SOSP},
  bibtex_show  = {true},
  author       = {Yuming Xu and
                  Hengyu Liang and
                  Jin Li and
                  Shuotao Xu and
                  Qi Chen and
                  Qianxi Zhang and
                  Cheng Li and
                  Ziyue Yang and
                  Fan Yang and
                  Yuqing Yang and
                  Peng Cheng and
                  Mao Yang},
  title        = {SPFresh: Incremental In-Place Update for Billion-Scale Vector Search},
  html         = {https://www.microsoft.com/en-us/research/publication/spfresh-incremental-in-place-update-for-billion-scale-vector-search/},
  booktitle    = {Proceedings of the 29th Symposium on Operating Systems Principles, {SOSP}},
  year         = {2023}
}

@inproceedings{DBLP:conf/eurosys/ZhaoHYZ0YZL0QZZ23,
  abbr         = {EuroSys},
  bibtex_show  = {true},
  author       = {Hanyu Zhao and
                  Zhenhua Han and
                  Zhi Yang and
                  Quanlu Zhang and
                  Mingxia Li and
                  Fan Yang and
                  Qianxi Zhang and
                  Binyang Li and
                  Yuqing Yang and
                  Lili Qiu and
                  Lintao Zhang and
                  Lidong Zhou},
  title        = {SiloD: {A} Co-design of Caching and Scheduling for Deep Learning Clusters},
  html         = {https://www.microsoft.com/en-us/research/publication/silod-a-co-design-of-caching-and-scheduling-for-deep-learning-clusters/},
  booktitle    = {Proceedings of the Eighteenth European Conference on Computer Systems, {EuroSys}},
  year         = {2023}  
}

@inproceedings{DBLP:conf/asplos/GuZZXHCYHJL23,
  abbr         = {ASPLOS},
  bibtex_show  = {true},
  author       = {Diandian Gu and
                  Yihao Zhao and
                  Yinmin Zhong and
                  Yifan Xiong and
                  Zhenhua Han and
                  Peng Cheng and
                  Fan Yang and
                  Gang Huang and
                  Xin Jin and
                  Xuanzhe Liu},
  title        = {ElasticFlow: An Elastic Serverless Training Platform for Distributed Deep Learning},\
  html={https://www.microsoft.com/en-us/research/publication/elasticflow-an-elastic-serverless-training-platform-for-distributed-deep-learning/},
  booktitle    = {Proceedings of the 28th {ACM} International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2, {ASPLOS}},
  year         = {2023}
}

@inproceedings{DBLP:conf/isca/0003THL00LG023,
  abbr         = {ISCA},
  bibtex_show  = {true},
  author       = {Cong Guo and
                  Jiaming Tang and
                  Weiming Hu and
                  Jingwen Leng and
                  Chen Zhang and
                  Fan Yang and
                  Yunxin Liu and
                  Minyi Guo and
                  Yuhao Zhu},
  title        = {OliVe: Accelerating Large Language Models via Hardware-friendly Outlier-Victim Pair Quantization},
  html={https://www.microsoft.com/en-us/research/publication/olive-accelerating-large-language-models-via-hardware-friendly-outlier-victim-pair-quantization/},
  booktitle    = {Proceedings of the 50th Annual International Symposium on Computer Architecture, {ISCA}},
  year         = {2023}
}

@inproceedings{DBLP:conf/nsdi/LiangFXYLZYZ23,
  abbr         = {NSDI},
  bibtex_show  = {true},
  author       = {Chieh{-}Jan Mike Liang and
                  Zilin Fang and
                  Yuqing Xie and
                  Fan Yang and
                  Zhao Lucis Li and
                  Li Lyna Zhang and
                  Mao Yang and
                  Lidong Zhou},
  title        = {On Modular Learning of Distributed Systems for Predicting End-to-End Latency},
  html={https://www.microsoft.com/en-us/research/publication/on-modular-learning-of-distributed-systems-for-predicting-end-to-end-latency/},
  booktitle    = {20th {USENIX} Symposium on Networked Systems Design and Implementation, {NSDI}},
  year         = {2023} 
}

@inproceedings{NEURIPS2023_ac112e8f,
  abbr         = {NeurIPS},
  bibtex_show  = {true},
  author = {Zhang, Hailin and Wang, Yujing and Chen, Qi and Chang, Ruiheng and Zhang, Ting and Miao, Ziming and Hou, Yingyan and Ding, Yang and Miao, Xupeng and Wang, Haonan and Pang, Bochen and Zhan, Yuefeng and Sun, Hao and Deng, Weiwei and Zhang, Qi and Yang, Fan and Xie, Xing and Yang, Mao and CUI, Bin},
  booktitle = {Advances in Neural Information Processing Systems, {NeurIPS}},
  html={https://www.microsoft.com/en-us/research/publication/model-enhanced-vector-index/},
  title = {Model-enhanced Vector Index},
  year = {2023}
}

@inproceedings{MLSYS2023_5616d34c,
  abbr         = {MLSys},
  bibtex_show  = {true},
  author = {Hwang, Changho and Cui, Wei and Xiong, Yifan and Yang, Ziyue and Liu, Ze and Hu, Han and Wang, Zilong and Salas, Rafael and Jose, Jithin and Ram, Prabhat and Chau, HoYuen and Cheng, Peng and Yang, Fan and Yang, Mao and Xiong, Yongqiang},
  booktitle = {Proceedings of Machine Learning and Systems, {MLSys}},
  editor = {D. Song and M. Carbin and T. Chen},
  pages = {269--287},
  publisher = {Curan},
  title = {Tutel: Adaptive Mixture-of-Experts at Scale},
  html = {https://proceedings.mlsys.org/paper_files/paper/2023/file/5616d34cf8ff73942cfd5aa922842556-Paper-mlsys2023.pdf},
  volume = {5},
  year = {2023}
}

@inproceedings{MLSYS2023_a10deb4d,
  abbr         = {MLSys},
  bibtex_show  = {true},
 author = {Lin, Bin and Zheng, Ningxin and Wang, Lei and Cao, Shijie and Ma, Lingxiao and Zhang, Quanlu and Zhu, Yi and Cao, Ting and Xue, Jilong and Yang, Yuqing and Yang, Fan},
 booktitle = {Proceedings of Machine Learning and Systems},
 editor = {D. Song and M. Carbin and T. Chen},
 pages = {513--525},
 publisher = {Curan},
 title = {Efficient GPU Kernels for N:M-Sparse Weights in Deep Learning},
 html = {https://proceedings.mlsys.org/paper_files/paper/2023/file/a10deb4d5227a8ea307ea8ff3cb712f4-Paper-mlsys2023.pdf},
 volume = {5},
 year = {2023}
}

@inproceedings{DBLP:conf/iclr/0003QLGZLY0G22,
  abbr         = {ICLR},
  bibtex_show  = {true},
  author       = {Cong Guo and
                  Yuxian Qiu and
                  Jingwen Leng and
                  Xiaotian Gao and
                  Chen Zhang and
                  Yunxin Liu and
                  Fan Yang and
                  Yuhao Zhu and
                  Minyi Guo},
  title        = {SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}},
  html={https://www.microsoft.com/en-us/research/publication/squant-on-the-fly-data-free-quantization-via-diagonal-hessian-approximation/},
  year         = {2022}
}

@inproceedings{DBLP:conf/micro/00030LL0LG022,
  abbr         = {MICRO},
  bibtex_show  = {true},
  author       = {Cong Guo and
                  Chen Zhang and
                  Jingwen Leng and
                  Zihan Liu and
                  Fan Yang and
                  Yunxin Liu and
                  Minyi Guo and
                  Yuhao Zhu},
  title        = {{ANT:} Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization},
  booktitle    = {55th {IEEE/ACM} International Symposium on Microarchitecture, {MICRO}},
  html={https://www.microsoft.com/en-us/research/publication/ant-exploiting-adaptive-numerical-data-type-for-low-bit-deep-neural-network-quantization/},
  award={Highlighted as an IEEE Micro Top Picks Honorable Mention in the [July/August special edition](https://ieeexplore.ieee.org/document/10167515) of IEEE Micro 2023},
  award_name={IEEE Micro Top Picks 2023 Honorable Mention},
  year         = {2022}
}

@inproceedings{DBLP:conf/osdi/ZhuWDKLZXMXC0YZ22,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Hongyu Zhu and
                  Ruofan Wu and
                  Yijia Diao and
                  Shanbin Ke and
                  Haoyu Li and
                  Chen Zhang and
                  Jilong Xue and
                  Lingxiao Ma and
                  Yuqing Xia and
                  Wei Cui and
                  Fan Yang and
                  Mao Yang and
                  Lidong Zhou and
                  Asaf Cidon and
                  Gennady Pekhimenko},
  title        = {{ROLLER:} Fast and Efficient Tensor Compilation for Deep Learning},
  html={https://www.microsoft.com/en-us/research/publication/roller-fast-and-efficient-tensor-compilation-for-deep-learning/},
  booktitle    = {16th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  year         = {2022}
}

@inproceedings{DBLP:conf/usenix/0149CH000SYG22,
  abbr         = {USENIX ATC},
  bibtex_show  = {true},
  author       = {Wei Zhang and
                  Binghao Chen and
                  Zhenhua Han and
                  Quan Chen and
                  Peng Cheng and
                  Fan Yang and
                  Ran Shu and
                  Yuqing Yang and
                  Minyi Guo},

  title        = {PilotFish: Harvesting Free Cycles of Cloud Gaming with Deep Learning
                  Training},
  booktitle    = {2022 {USENIX} Annual Technical Conference, {USENIX} {ATC}},
  html={https://www.microsoft.com/en-us/research/publication/pilotfish-harvesting-free-cycles-of-cloud-gaming-with-deep-learning-training/},
  year         = {2022}
}

@inproceedings{DBLP:conf/osdi/ZhengLZMY0WYZ22,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Ningxin Zheng and
                  Bin Lin and
                  Quanlu Zhang and
                  Lingxiao Ma and
                  Yuqing Yang and
                  Fan Yang and
                  Yang Wang and
                  Mao Yang and
                  Lidong Zhou},
  title        = {Spar{TA}: Deep-Learning Model Sparsity via Tensor-with-Sparsity-Attribute},
  booktitle    = {16th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},  
  html={https://www.microsoft.com/en-us/research/publication/sparta-deep-learning-model-sparsity-via-tensor-with-sparsity-attribute/},
  year         = {2022}
}

@inproceedings{10.1145/3477495.3531799,
abbr         = {SIGIR},
bibtex_show  = {true}, 
author = {Xiao, Shitao and Liu, Zheng and Han, Weihao and Zhang, Jianjin and Lian, Defu and Gong, Yeyun and Chen, Qi and Yang, Fan and Sun, Hao and Shao, Yingxia and Xie, Xing},
title = {Distill-VQ: Learning Retrieval Oriented Vector Quantization By Distilling Knowledge from Dense Embeddings},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
html = {https://doi.org/10.1145/3477495.3531799},
doi = {10.1145/3477495.3531799},
abstract = {Vector quantization (VQ) based ANN indexes, such as Inverted File System (IVF) and Product Quantization (PQ), have been widely applied to embedding based document retrieval thanks to the competitive time and memory efficiency. Originally, VQ is learned to minimize the reconstruction loss, i.e., the distortions between the original dense embeddings and the reconstructed embeddings after quantization. Unfortunately, such an objective is inconsistent with the goal of selecting ground-truth documents for the input query, which may cause severe loss of retrieval quality. Recent works identify such a defect, and propose to minimize the retrieval loss through contrastive learning. However, these methods intensively rely on queries with ground-truth documents, whose performance is limited by the insufficiency of labeled data. In this paper, we propose Distill-VQ, which unifies the learning of IVF and PQ within a knowledge distillation framework. In Distill-VQ, the dense embeddings are leveraged as "teachers'', which predict the query's relevance to the sampled documents. The VQ modules are treated as the "students'', which are learned to reproduce the predicted relevance, such that the reconstructed embeddings may fully preserve the retrieval result of the dense embeddings. By doing so, Distill-VQ is able to derive substantial training signals from the massive unlabeled data, which significantly contributes to the retrieval quality. We perform comprehensive explorations for the optimal conduct of knowledge distillation, which may provide useful insights for the learning of VQ based ANN index. We also experimentally show that the labeled data is no longer a necessity for high-quality vector quantization, which indicates Distill-VQ's strong applicability in practice. The evaluations are performed on MS MARCO and Natural Questions benchmarks, where Distill-VQ notably outperforms the SOTA VQ methods in Recall and MRR. Our code is avaliable at https://github.com/staoxiao/LibVQ.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1513–1523},
numpages = {11},
keywords = {approximate nearest neighbour search, embedding based retrieval, knowledge distillation, vector quantization},
location = {Madrid, Spain},
series = {SIGIR '22}
}

@InProceedings{10.1007/978-3-031-19787-1_41,
  abbr         = {ECCB},
  bibtex_show  = {true},
author="Wu, Chenfei
and Liang, Jian
and Ji, Lei
and Yang, Fan
and Fang, Yuejian
and Jiang, Daxin
and Duan, Nan",
editor="Avidan, Shai
and Brostow, Gabriel
and Ciss{\'e}, Moustapha
and Farinella, Giovanni Maria
and Hassner, Tal",
title="N{\"U}WA: Visual Synthesis Pre-training for Neural visUal World creAtion",
booktitle="Computer Vision -- ECCV 2022",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="720--736",
abstract="This paper presents a unified multimodal pre-trained model called N{\"U}WA that can generate new or manipulate existing visual data (i.e., images and videos) for various visual synthesis tasks. To cover language, image, and video at the same time for different scenarios, a 3D transformer encoder-decoder framework is designed, which can not only deal with videos as 3D data but also adapt to texts and images as 1D and 2D data, respectively. A 3D Nearby Attention (3DNA) mechanism is also proposed to consider the nature of the visual data and reduce the computational complexity. We evaluate N{\"U}WA on 8 downstream tasks. Compared to several strong baselines, N{\"U}WA achieves state-of-the-art results on text-to-image generation, text-to-video generation, video prediction, etc. Furthermore, it also shows surprisingly good zero-shot capabilities on text-guided image and video manipulation tasks.",
isbn="978-3-031-19787-1"
}

@inproceedings{DBLP:conf/asplos/PengSD0MXYQ20,
  abbr         = {ASPLOS},
  bibtex_show  = {true},
  author       = {Xuan Peng and
                  Xuanhua Shi and
                  Hulin Dai and
                  Hai Jin and
                  Weiliang Ma and
                  Qian Xiong and
                  Fan Yang and
                  Xuehai Qian},
  title        = {Capuchin: Tensor-based {GPU} Memory Management for Deep Learning},
  booktitle    = {{ASPLOS} '20: Architectural Support for Programming Languages and Operating Systems, {ASPLOS}},
  html={https://www.microsoft.com/en-us/research/publication/capuchin-tensor-based-gpu-memory-management-for-deep-learning/},
  year         = {2020}
}

@inproceedings{DBLP:conf/osdi/ZhaoHYZYZYLWXW20,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Hanyu Zhao and
                  Zhenhua Han and
                  Zhi Yang and
                  Quanlu Zhang and
                  Fan Yang and
                  Lidong Zhou and
                  Mao Yang and
                  Francis C. M. Lau and
                  Yuqi Wang and
                  Yifan Xiong and
                  Bin Wang},
  title        = {Hive{D}: Sharing a {GPU} Cluster for Deep Learning with Guarantees},
  booktitle    = {14th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  html={https://www.microsoft.com/en-us/research/publication/hived-sharing-a-gpu-cluster-for-deep-learning-with-guarantees/},
  year         = {2020}
}

@inproceedings{DBLP:conf/osdi/MaXYXMCHYZZ20,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Lingxiao Ma and
                  Zhiqiang Xie and
                  Zhi Yang and
                  Jilong Xue and
                  Youshan Miao and
                  Wei Cui and
                  Wenxiang Hu and
                  Fan Yang and
                  Lintao Zhang and
                  Lidong Zhou},
  title        = {Rammer: Enabling Holistic Deep Learning Compiler Optimizations with rTasks},
  booktitle    = {14th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  html={https://www.microsoft.com/en-us/research/publication/rammer-enabling-holistic-deep-learning-compiler-optimizations-with-rtasks/},
  year         = {2020} 
}

@inproceedings{DBLP:conf/osdi/ZhangHYZLYZ20,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Quanlu Zhang and
                  Zhenhua Han and
                  Fan Yang and
                  Yuge Zhang and
                  Zhe Liu and
                  Mao Yang and
                  Lidong Zhou},
  title        = {Retiarii: {A} Deep Learning Exploratory-Training Framework},
  booktitle    = {14th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  html={https://www.microsoft.com/en-us/research/publication/retiarii-a-deep-learning-exploratory-training-framework/},
  year         = {2020}
}

@inproceedings{DBLP:conf/usenix/JeonVPQXY19,
  abbr         = {USENIX ATC},
  bibtex_show  = {true},
  author       = {Myeongjae Jeon and
                  Shivaram Venkataraman and
                  Amar Phanishayee and
                  Junjie Qian and
                  Wencong Xiao and
                  Fan Yang},
  title        = {Analysis of Large-Scale Multi-Tenant {GPU} Clusters for {DNN} Training
                  Workloads},
  booktitle    = {2019 {USENIX} Annual Technical Conference, {USENIX} {ATC}},
  year         = {2019} 
}

@inproceedings{DBLP:conf/osdi/XiaoBRSKHPPZZYZ18,
  abbr         = {OSDI},
  bibtex_show  = {true},
  author       = {Wencong Xiao and
                  Romil Bhardwaj and
                  Ramachandran Ramjee and
                  Muthian Sivathanu and
                  Nipun Kwatra and
                  Zhenhua Han and
                  Pratyush Patel and
                  Xuan Peng and
                  Hanyu Zhao and
                  Quanlu Zhang and
                  Fan Yang and
                  Lidong Zhou},
  title        = {Gandiva: Introspective Cluster Scheduling for Deep Learning},
  booktitle    = {13th {USENIX} Symposium on Operating Systems Design and Implementation, {OSDI}},
  year         = {2018}
}

@inproceedings{10.1145/2806777.2806849,
abbr         = {SoCC},
bibtex_show  = {true},
author = {Wu, Ming and Yang, Fan and Xue, Jilong and Xiao, Wencong and Miao, Youshan and Wei, Lan and Lin, Haoxiang and Dai, Yafei and Zhou, Lidong},
title = {GraM: scaling graph computation to the trillions},
year = {2015},
isbn = {9781450336512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
html = {https://doi.org/10.1145/2806777.2806849},
doi = {10.1145/2806777.2806849},
abstract = {GraM is an efficient and scalable graph engine for a large class of widely used graph algorithms. It is designed to scale up to multicores on a single server, as well as scale out to multiple servers in a cluster, offering significant, often over an order-of-magnitude, improvement over existing distributed graph engines on evaluated graph algorithms. GraM is also capable of processing graphs that are significantly larger than previously reported. In particular, using 64 servers (1,024 physical cores), it performs a PageRank iteration in 140 seconds on a synthetic graph with over one trillion edges, setting a new milestone for graph engines.GraM's efficiency and scalability comes from a judicious architectural design that exploits the benefits of multi-core and RDMA. GraM uses a simple message-passing based scaling architecture for both scaling up and scaling out to expose inherent parallelism. It further benefits from a specially designed multi-core aware RDMA-based communication stack that preserves parallelism in a balanced way and allows overlapping of communication and computation. A high degree of parallelism often comes at the cost of lower efficiency due to resource fragmentation. GraM is equipped with an adaptive mechanism that evaluates the cost and benefit of parallelism to decide the appropriate configuration. Combined, these mechanisms allow GraM to scale up and out with high efficiency.},
booktitle = {Proceedings of the Sixth ACM Symposium on Cloud Computing, {SoCC}},
pages = {408–421},
numpages = {14},
keywords = {RDMA, graph computation engine, scalability},
location = {Kohala Coast, Hawaii},
series = {SoCC '15}
}

@article{10.1145/2700302,
abbr         = {ToS},
bibtex_show  = {true},
author = {Miao, Youshan and Han, Wentao and Li, Kaiwei and Wu, Ming and Yang, Fan and Zhou, Lidong and Prabhakaran, Vijayan and Chen, Enhong and Chen, Wenguang},
title = {ImmortalGraph: A System for Storage and Analysis of Temporal Graphs},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1553-3077},
html = {https://doi.org/10.1145/2700302},
doi = {10.1145/2700302},
abstract = {Temporal graphs that capture graph changes over time are attracting increasing interest from research communities, for functions such as understanding temporal characteristics of social interactions on a time-evolving social graph. ImmortalGraph is a storage and execution engine designed and optimized specifically for temporal graphs. Locality is at the center of ImmortalGraph’s design: temporal graphs are carefully laid out in both persistent storage and memory, taking into account data locality in both time and graph-structure dimensions. ImmortalGraph introduces the notion of locality-aware batch scheduling in computation, so that common “bulk” operations on temporal graphs are scheduled to maximize the benefit of in-memory data locality. The design of ImmortalGraph explores an interesting interplay among locality, parallelism, and incremental computation in supporting common mining tasks on temporal graphs. The result is a high-performance temporal-graph system that is up to 5 times more efficient than existing database solutions for graph queries. The locality optimizations in ImmortalGraph offer up to an order of magnitude speedup for temporal iterative graph mining compared to a straightforward application of existing graph engines on a series of snapshots.},
journal = {ACM Trans. Storage},
month = {jul},
articleno = {14},
numpages = {34},
keywords = {temporal graph, graph algorithms, Concurrent computing}
}

@inproceedings{10.1145/2592798.2592799,
abbr         = {EuroSys},
bibtex_show  = {true},
author = {Han, Wentao and Miao, Youshan and Li, Kaiwei and Wu, Ming and Yang, Fan and Zhou, Lidong and Prabhakaran, Vijayan and Chen, Wenguang and Chen, Enhong},
title = {Chronos: a graph engine for temporal graph analysis},
year = {2014},
isbn = {9781450327046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
html = {https://doi.org/10.1145/2592798.2592799},
doi = {10.1145/2592798.2592799},
abstract = {Temporal graphs capture changes in graphs over time and are becoming a subject that attracts increasing interest from the research communities, for example, to understand temporal characteristics of social interactions on a time-evolving social graph. Chronos is a storage and execution engine designed and optimized specifically for running in-memory iterative graph computation on temporal graphs. Locality is at the center of the Chronos design, where the in-memory layout of temporal graphs and the scheduling of the iterative computation on temporal graphs are carefully designed, so that common "bulk" operations on temporal graphs are scheduled to maximize the benefit of in-memory data locality. The design of Chronos further explores the interesting interplay among locality, parallelism, and incremental computation in supporting common mining tasks on temporal graphs. The result is a high-performance temporal-graph system that offers up to an order of magnitude speedup for temporal iterative graph mining compared to a straightforward application of existing graph engines on a series of snapshots.},
booktitle = {Proceedings of the Ninth European Conference on Computer Systems},
articleno = {1},
numpages = {14},
location = {Amsterdam, The Netherlands},
series = {EuroSys '14}
}

@inproceedings{10.1145/2168836.2168846,
abbr         = {EuroSys},
bibtex_show  = {true},
author = {Cheng, Raymond and Hong, Ji and Kyrola, Aapo and Miao, Youshan and Weng, Xuetian and Wu, Ming and Yang, Fan and Zhou, Lidong and Zhao, Feng and Chen, Enhong},
title = {Kineograph: taking the pulse of a fast-changing and connected world},
year = {2012},
isbn = {9781450312233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
html = {https://doi.org/10.1145/2168836.2168846},
doi = {10.1145/2168836.2168846},
abstract = {Kineograph is a distributed system that takes a stream of incoming data to construct a continuously changing graph, which captures the relationships that exist in the data feed. As a computing platform, Kineograph further supports graph-mining algorithms to extract timely insights from the fast-changing graph structure. To accommodate graph-mining algorithms that assume a static underlying graph, Kineograph creates a series of consistent snapshots, using a novel and efficient epoch commit protocol. To keep up with continuous updates on the graph, Kineograph includes an incremental graph-computation engine. We have developed three applications on top of Kineograph to analyze Twitter data: user ranking, approximate shortest paths, and controversial topic detection. For these applications, Kineograph takes a live Twitter data feed and maintains a graph of edges between all users and hashtags. Our evaluation shows that with 40 machines processing 100K tweets per second, Kineograph is able to continuously compute global properties, such as user ranks, with less than 2.5-minute timeliness guarantees. This rate of traffic is more than 10 times the reported peak rate of Twitter as of October 2011.},
booktitle = {Proceedings of the 7th ACM European Conference on Computer Systems},
pages = {85–98},
numpages = {14},
keywords = {distributed storage, graph processing},
location = {Bern, Switzerland},
series = {EuroSys '12}
}
