<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A podcast on AI reasoning | Fan Yang </title> <meta name="author" content="Fan Yang"> <meta name="description" content="How to fill the seemingly insurmountable gap between “correlation” and “causality”"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.jpg?2d4592c1cc4d93aae8657237c27067f1"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fanyangcs.github.io/blog/2025/OnAIReasoning/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Fan</span> Yang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">A podcast on AI reasoning</h1> <p class="post-meta"> Created in December 05, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Recently, I was on a <a href="https://fanyangcs.github.io/news/AIReasoningPodcast/">podcast</a> discussing AI reasoning. Below is the transcript of the podcast. It is in Chinese. I will see if I get a chance to have an English version.</p> <hr> <h4 id="背景">背景：</h4> <p><em> 一提到“推理”，很多人第一反应可能是侦探小说里的福尔摩斯：通过蛛丝马迹一步步找出真相。人类的推理确实是这样，我们会依靠逻辑、常识和经验，从已知条件出发，逐步得出结论。</em></p> <p>那 AI 的推理呢？它当然不会去破案，但它要面对的，其实是类似的过程：从已有信息里，分析出合理的结果，甚至能够延伸出新的可能性。比如，你对一个智能助手说：“今天下雨了，我要出门”，它如果只回答“带伞”，这其实还不算推理；但如果它能继续想到“可能要穿防水外套”，“雨天路滑可以考虑公共交通”，这就是在做更接近人类的推理。</p> <p>但是，AI的推理能力也不是一开始就这么强的。在AI发展的历史中，我们通常把AI推理分为两个主要阵营：</p> <p>第一个是“符号推理”（Symbolic Reasoning）。这是比较传统的方法。你可以想象一下，它就是给AI设定了一堆严谨的逻辑规则，比如“如果 A 成立，并且 B 成立，那么 C 就成立”。它的优点是严谨、可解释，你可以清楚地知道AI是怎么得出结论的。但它的缺点也很明显：现实世界太复杂了，很难穷尽所有规则，而且面对不确定的、模糊的问题时，它就束手无策了。</p> <p>第二个是“非符号推理”（Non-symbolic Reasoning），这主要基于数据进行学习，通过神经网络发现数据中的隐藏模式。像我们现在经常听到的大语言模型，它们的推理能力就属于这一类。它不像符号推理那样有一条条清晰的逻辑链，更像是一种“直觉”。它在海量数据中看到了无数次“下雨”和“带伞”的关联，所以当你说“下雨”时，它就能“直觉”地给出“带伞”这个答案。它的优点是擅长处理复杂、开放的问题，但有时也会犯一些低级错误，甚至给出看似合理但实际上是错误的回答，也就是我们常说的“幻觉”。</p> <p>这两种方法各有优势和短板。而现在最前沿的研究，就是如何把它们结合起来，让AI既能有强大的“直觉”，又能进行严密的“逻辑”思考。</p> <p>带着这个背景，我们就更容易理解后面要聊的内容了。好了，话不多说，让我们进入今天的正题吧！ &lt;/em&gt;</p> <h4 id="对话环节">对话环节：</h4> <h5 id="主持人">主持人</h5> <p>杨凡博士你好，现在我们先从一个基础的问题聊起。很多听众对“推理”的理解可能还停留在人类的逻辑推理层面，比如福尔摩斯那样的逻辑推理。那么在人工智能的语境下，我们说的“AI推理”和传统意义上的逻辑推理，到底有什么本质区别呢？能不能理解为，AI推理更多是基于大数据的概率性归纳？</p> <h6 id="我">我</h6> <p>这个问题非常有意思。其实从某种意义上来说，AI推理和逻辑推理就像人工智能和人类智能的区别一样。人工智能研究的目标，就是希望做到接近人类智能的水平。而推理能力正是智能最本质的体现之一，所以这也是我们对智能特别感兴趣的一个原因。</p> <p>根据维基百科的介绍，推理就是从大量信息中得出结论的能力。如果得出的结论是令人信服的，那它就需要一定的逻辑。换句话说，为了保证推理的正确性，就需要遵循一些比较严谨的过程，这就是逻辑。从抽象层面上说，它可以用数学来表达。</p> <p>很多人会觉得大语言模型的推理是基于概率统计的大数据归纳。这牵涉到统计方面的一个本质问题：从大数据中归纳出来的现象，究竟意味着什么？是纯粹的相关性，还是因果性？如果只是相关性，那AI推理就不应该有因果性，可推理本身就是基于因果性的。</p> <p>如果AI 是基于大数据的归纳，它只是浮现出相关性，那么就不应该展现出强大的推理能力。现在的AI推理确实经常犯错，但它在过去两年的发展中，推理正确性也越来越高。而且以人类的知识来检验的话，它这中间展现出的因果性是相当惊人的。为什么会展现出这样的一种特性，以及这种特性能走多远？</p> <p>现在学界对这个问题并没有统一答案。我个人更倾向认为，在基于概率的模型上，我们仍然有机会把推理做到一个很高的水准，甚至达到实用层面。比如说，在初高中层面的逻辑和数学题上，大模型如果展现出相当可靠的推理能力，那么就有可能在实际应用里发挥价值。</p> <p>至于AI推理和传统意义上的人类推理的区别，我觉得目前还没有明确答案。就像人工智能和人类智能之间的差异一样，我们只知道人脑的生物学结构和大模型的构造完全不一样。但这并不意味着它们不能共享某些特性。</p> <p>我更愿意把智能看成是一件很“纯粹的事”， 智能就是智能，你可以用方法A来实现智能，也可以用方法B来实现。人类和大模型就是实现智能的两种不同方式，其中可能存在相关性。这是我现在的一个看法。</p> <h5 id="主持人-1">主持人</h5> <p>你提到推理的正确性，这让我想到另一个问题。很多人觉得“推理就是让大模型更聪明”。可在学术界和工业界，大家又特别关注计算速度。那么 ，你怎么看推理速度和智能之间的关系？</p> <h5 id="我-1">我</h5> <p>我觉得只有正确的推理才能算聪明，尤其是面对复杂问题的时候，能得出正确答案才是真正的智能。人和 AI 都会在速度和质量之间做平衡。对于一些问题，我们都希望得到对的答案。但想得快却经常出错，其实没有意义。大语言模型也是一样，光快不够，必须尽量保证推理正确。</p> <p>当然，速度在推理中也非常重要。很多复杂问题可能需要成千上万步的推理步骤，如果每一步都很慢，那最终问题也解不出来。而且人也不会等这么长时间，大多数情况下，我们还是希望答案尽快出来。</p> <p>另外，如果在一些相对简单的问题上都思考得很慢，那别人也很难相信你在复杂问题上即使坚持长时间能给出结果。我们通常觉得一个人聪明表现为思考非常快，当然回答也是对的。</p> <p>所以从智能的角度来说，速度和质量之间确实有一个微妙的平衡，不能做极端的选择。</p> <h5 id="主持人-2">主持人</h5> <p>非常清晰的观点。所以在推理能力上，既要准确，也要兼顾速度，两者确实需要平衡。那接下来聊一聊你团队的研究方向。你的团队最近在探索新的推理方式，能不能给我们介绍一下研究内容？这些方法和传统的深度学习推理相比，最大的突破点在哪里？在实验过程中有没有什么让你们出乎意料的发现？</p> <h5 id="我-2">我</h5> <p>我们现在在探讨的一个推理范式叫做 neural symbolic reasoning。Neural 就是神经，symbolic 就是符号主义的推导。其实这个范式并不算新，人工智能早期就有符号主义和连接主义的争论。在很长一段时间里，符号主义占优势，因为连接主义没有展现出让人兴奋的结果。某种意义上，今天的计算科学很多知识都还是属于符号主义的范畴。</p> <p>随着大语言模型的兴起，连接主义在一些传统计算机难以解决的问题上展现出惊人的实力，比如语音识别、图像识别和自然语言理解等等。这是传统计算机做不到的。于是现在大家普遍认为，连接主义，也就是大语言模型，可能是走向 AI最重要的技术路径。</p> <p>在这样的范式下，研究社区都在追求所谓的 scaling law，就是追求模型规模、训练数据规模和计算规模，把这三者进一步扩展，智能表现就会不断提升。去年下半年，大家又注意到了时间因素，我称之为scaling law的第四维度。这被称为 test-time scaling，也就是说，模型思考的时间越长，它的智能水平往往越高。</p> <p>我们团队在一两年前就开始关注这种推理范式。当时有两个很朴素的想法。第一，scaling law 本身很符合人类直觉，比如人的大脑容量比其他动物大，神经元数量更多，这完全符合scaling law，所以我们的智能表现就比别的更好了，对吧？</p> <p>第二个维度是数据，然后就是计算力。你要思考的时候，你需要的这个脑力是很高的。这个脑力就相当于计算力。我们那个时候就觉得人类进一步提高，那不就是要思考的久一点吗？所以，当时这个范式还没有出现的时候，我们就认为我们肯定是要在脑子中不断思考。我们当时把这种范式称之为 self-play，也就是在脑中不断演练思考。我们去年的成果第一次用公开的方法告诉大家self-play，或者说所谓的test time scaling是怎么样提升智能的。这也是我们觉得探索智能进步的路径可以参考人类的一个原因。</p> <p>我们还思考neural symbolic reasoning。这是什么意思呢？我们认为从符号主义和连接主义的角度来讲，他们可能是一种互补关系。那时我们看到大语言模型推理肯定有很多很多问题，对吧？毕竟两年前大语言模型推理水平还停留在小学阶段，现在已经可以把奥林匹克的数学竞赛的金牌都给赢下来。我们当时也并不是认为大语言模型做不到，只是它也像人一样需要一个“脚手架”。 也就是用符号化的工具来帮助大语言模型在推理的时候做一种验证，所谓的verification，有了这个verification，那么就能极大地提高推理的可靠性。</p> <p>人类也会犯错，但我们可以通过复核、老师批改、甚至借助工具来验证，对吧？比如人类经常用的一些工具，比如数学的工具，像计算器。对 AI 来说，我们大量使用了自动定理证明来做验证。我们目前来讲的话，看到的这个范式也是起到了一个作用。</p> <p>事实上，研究社区里现在也在讨论类似的方向，虽然名字可能不同，比如有人叫 self-verifiable learning，但本质是一样的。推理在数学领域是相对比较容易被验证的，所以你会看到现在前沿的大模型都在打数学竞赛、编程比赛。这也是因为这些领域可以提供清晰的验证标准。</p> <p>所以我认为我们过去探索的这些方向算不上新的范式，而是沿着智能演进路径做出的自然推演。现在业界其实也逐渐达成了某种共识。</p> <p>至于未来会怎样？我觉得会碰到一个问题是：这些方向够不够？大语言模型的推理能力在一些难题上已经展现出很高水平，但它仍然会在一些非常简单的问题上出错。比如 GPT-5 发布时，有人问它“美国50个州里哪些州名字里包含字母 R”，结果它没答对。</p> <p>另外，它在最困难的数学推理上，还是和顶尖人类有差距。比如说，今年国际奥林匹克数学竞赛一共有六道题，AI 能解出前五题，但第六题没有任何模型能做出来。IMO 美国教练埃文还专门点评过，说前五题算相对容易，最难的是第六题。所以在深度推理上，AI 还有很长的路要走。</p> <p>你刚才问有没有让我们觉得意外的实验结果？其实让我感触最深的是：研究智能突破时，一定要避免方法过于精巧。太过精巧的话，容易导致模型出现 reward hacking，或者过拟合。真正有效的，往往是足够简单、具备通用性和泛化性。复杂的规则通常走不远。</p> <p>这点其实和 Richard Sutton 提出的 The Bitter Lesson 是呼应的：过去几十年里，精巧的算法是没有强大的算力有效果的。</p> <h5 id="主持人-3">主持人</h5> <p>听起来，你们的研究既关注大方向上的规律，又非常强调方法的朴素性和普适性。那么，关于现在推理能力发展的瓶颈。从研究角度看，目前推理的主要难点在哪里？是数据不足、算法局限，还是硬件资源的限制呢？</p> <h5 id="我-3">我</h5> <p>是的，我们现在看到的情况是，过去几年里，智能的发展主要遵循“scaling law”，也就是算力、数据、模型规模，还有时间。这也是我们前面回顾过的一条智能进步路线。</p> <p>但问题在于，这几个维度现在都进入了瓶颈。什么意思呢？就是虽然智能能随着scaling law进步，但大家发现scaling law本身是log-scale的。也就是说，你需要投入十倍的资源，才能换来一点点提升。资源消耗是指数级增长，但智能的提升往往只有线性增长。很多研究都已经显示出了这种情况。所以我们觉得，要想往前走得远，就必须找到scaling law之外的新范式。</p> <p>我们希望从人类提高智能的方式中提取一些新猜想。我们的猜想从一个非常聪明、受过良好训练的博士生开始。他符合scaling law的四个维度，他的大脑容量很强大，他博学，受过数十年严谨训练，学过大量知识，很擅长思考。</p> <p>但为什么他还要继续读博士、跟随导师训练？就是因为光有知识和能力还不够，他需要导师的引导。导师通常不会只是灌输知识，而是通过不断布置任务、提出问题来帮助学生训练思维。我们就在想，能不能模仿这种模式来训练大语言模型，让它也能突破scaling law瓶颈。</p> <p>所以我们在实验中尝试过这种“引导式”的方法。面对一个复杂的问题时，我们不要求模型直接给出答案，而是引导它先做计划，把复杂问题分解成步骤，再对每个步骤细化并逐一实现和验证。</p> <p>这是一个非常有意思的实验。结果让我们很惊讶，就是用一个这样简单的一个个约束性的引导性的问题，模型在数学推理上面的能力是出现了飞跃。我们在今年六月做的这个实验，发现它能在没有额外训练的情况下，达到当时顶级模型的水平。这让我们很有信心，相信这种方式可能帮助大模型突破当前的瓶颈。</p> <p>大语言模型现在之所以会犯一些很糟糕甚至很愚蠢的错误，或者无法解决复杂的问题，原因可能是一样的：它缺乏把问题抽象出来的能力，也就是泛化能力还不够强。它可能见过很多例子，但却没办法从例子里总结出更高阶的规律。所以我们应该通过这种引导方式，把它潜在的抽象和规划能力激发出来。</p> <p>另一个可能出现突破的方向，就是我们认为模型在处理复杂问题时，需要额外的机制辅助。我把它称为“长期记忆”。就像大脑依靠海马体储存长期记忆一样，大语言模型也需要长期记忆。现在它们已经有了“上下文窗口”，很多团队，包括我们自己，都在努力把窗口做得更大，因为窗口越大，能利用的信息就越多，思考也能更久。</p> <p>但我们发现，像注意力机制这样的设计并不是完美的，它可能带来很多噪音。噪音在处理复杂问题时会成为致命弱点。所以我们设想，如果能把上下文窗口中的信息做处理、去噪，然后把关键的信息存储到长期记忆里，不仅能解决当前问题，还能对未来的问题提供帮助。</p> <p>所以我觉得，长期记忆机制可能是提升大语言模型推理能力的另一个重要机遇。</p> <p>我们将上面几种思路总结成为一种新范式，称之为agentic reasoning：基于智能体的AI推理。</p> <h5 id="主持人-4">主持人</h5> <p>你们在做推理研究时会考虑和现实任务结合，比如说代码的生成，复杂问题等等。你怎么看推理在整个AI系统里以及这些具体应用中的价值？</p> <h5 id="我-4">我</h5> <p>这是个好问题。我觉得推理能力其实就是智能能力突出体现的一个方向。Satya 最近有句话我很认同：就是说AI 能力再高，你最终还是要在GDP的增长中体现出来。换句话说，一个人的推理能力再高，也要在具体的生产活动中得到体现，那才是有用的对吧？</p> <p>很明显推理是一个很核心的能力，在绝大多数的生产活动中都需要推理。你很难想象有多少工作是不需要推理的，尤其是面对复杂问题的时候。所以推理绝对是在所有的应用中是有非常大的一个价值。</p> <h5 id="主持人-5">主持人</h5> <p>我们接着聊下一个比较热的话题，就是“通用推理能力”。它意味着模型在跨任务、跨领域时都能灵活地进行逻辑推导。在你看来，这个目标离我们还有多远？</p> <h5 id="我-5">我</h5> <p>其实这个问题和上一个问题是相关的。把推理能力放到不同场景去用，自然就要所谓的通用推理能力。我觉得通用推理的基础还是推理，也就是说推理必须是对的，就得有逻辑。这也是为什么我们认为从数学角度训练AI的数学推理能力是非常本质的。如果它能在数学上能做到很严谨，那么它就更有可能把这种能力泛化到别的领域。就像数学系的学生去做别的事情，通常也能相对适应，但仍需要一些额外的训练。</p> <h5 id="主持人-6">主持人</h5> <p>嗯，听上去数学像是一种“通用底座”。那是不是说数学一强就万事大吉了？</p> <h5 id="我-6">我</h5> <p>这并不意味着数学推理能力很高了以后，它能自动在所有领域都达到很强的通用推理能力。这还牵涉到大量跨领域的知识获取问题。很多领域有自己的“行规”，有些甚至是私有的，比如公司的内部商业逻辑，这类信息通常不公开。在没有这些数据的情况下，怎么把一个有很强的通用推理能力的AI用好？这仍然有很多研究问题需要解决。</p> <h5 id="主持人-7">主持人</h5> <p>明白了。那我们换个角度聊聊。推理听起来挺“高冷”的，但其实和人类思维有不少联系。你觉得在人类的这些机制里，比如反思（reflection）、因果（causality）、常识（common sense），哪些最值得在推理中借鉴和实现？</p> <h5 id="我-7">我</h5> <p>这是个好问题。我觉得推理是个很宽泛的概念。我们自己在具体的实验中发现，如果要有很强的推理能力，就需要很多人类思维里的高阶思考能力。比如反思，这是目前观察到的一个重要的机制。</p> <p>另外，创造性在推理中也很重要。实际上在越困难的问题中，创造性越重要。因为越困难就代表着常规的思路、常识可能已经很难解决了。这时候就需要“跳出框架”的思维，也就是创造性。还有刚才提到的好的抽象能力，这个推理才能有足够的泛化能力。以及，在处理复杂问题时，需要好的规划能力。所以几乎所有人类思维中的核心机制，在推理中都有所体现。</p> <p>如果缺乏常识，就容易犯很低级的错误，这其实就是常识不足的体现。至于因果，这是一个更复杂的问题。我们能不能真的从看似相关的现象里推导出因果，这在学术界一直有争议。</p> <p>从传统统计学派到其他学派，各自观点都不一样。大语言模型就是这种争议的一个矛盾体现：它好像在某些时候能表现出因果推理的能力，但严格来说它还是基于相关性。这也是为什么有人认为它只是“模拟推理”，而不是在真正理解因果。</p> <h5 id="主持人-8">主持人</h5> <p>对，它不一定是有因果关系，只不过是这两个有关联，对吧？</p> <h5 id="我-8">我</h5> <p>对，普遍的共识是，关联和因果在本质上是不一样的东西。所以你不可能仅仅通过观察关联，就真正理解这个推理。如果真是这样，那 AI 可能永远没有能力理解所谓的因果关系。</p> <p>我的想法是，即使它不理解，但依然能解决非常复杂的问题，那对我们来说又有什么区别呢？从实用主义的角度来看，下面这个问题值得思考：你究竟要关心它是不是理解了，还是更关心它能不能帮你解决现实问题？这就是我的一些看法。</p> <h5 id="主持人-9">主持人</h5> <p>嗯，很有意思。那最后一个问题，咱们稍微展望一下未来。如果把时间加速到三到五年以后，你觉得推理技术最可能带来的质变会体现在哪些方面？</p> <h5 id="我-9">我</h5> <p>说实话，我也没法准确预测，只能猜测一下。现在的大语言模型表现出两种看似矛盾的现象。一方面，它的推理能力已经很强，强到普通人很难判断。在某些专业领域，它的表现已经超过大多数人。所以很难再去分辨它的能力是不是还在继续提升。但实际上，它确实在提高。</p> <p>但另一方面，它依然会在一些很简单的地方犯错，而这些低级错误是普通人最容易感知的。我猜想三到五年后，模型可能还会犯这种错误，但概率会越来越低。但因为用户规模太大，这些错误依然会被放大。与此同时，它在一些专业领域的推理能力会进一步提升，可能沿着我们刚才提到的技术路径发展。</p> <p>我相信未来三到五年，推理技术一定会更深入地进入现实生产环节，切实提高生产力。这几乎是一个高概率的趋势。</p> <h4 id="结束语">结束语：</h4> <p>好的，今天的对话真的是信息量很大。从推理的基本概念，到速度和准确性的平衡，再到符号主义和连接主义的结合，还有未来可能突破的方向，杨博士都分享了很多深入的思考。</p> <p>我们也期待看到三到五年后，推理技术能更深刻地改变我们的工作和生活。</p> <p>感谢杨凡博士带来的分享，也感谢大家的收听，希望我们的节目能帮你更好地理解AI技术。如果你喜欢这期节目，欢迎订阅和分享《AI Next》。我们会在接下来的节目里，继续带你探索人工智能的前沿。下期再见！</p> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Fan Yang. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-news",title:"news",description:"",section:"Navigation",handler:()=>{window.location.href="/news/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"my current and past research projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-a-podcast-on-ai-reasoning",title:"A podcast on AI reasoning",description:"How to fill the seemingly insurmountable gap between \u201ccorrelation\u201d and \u201ccausality\u201d",section:"Posts",handler:()=>{window.location.href="/blog/2025/OnAIReasoning/"}},{id:"post-the-dollar-per-token-business",title:"The \u201cdollar per token\u201d business",description:"where there&#39;s tension, there&#39;s opportunity; the economics of AI",section:"Posts",handler:()=>{window.location.href="/blog/2025/dollartokenbusiness/"}},{id:"post-to-prospective-interns",title:"To prospective interns",description:"a note to students curious about systems research",section:"Posts",handler:()=>{window.location.href="/blog/2024/intern/"}},{id:"post-on-annual-performance-review",title:"On annual performance review",description:"performance review is hard ...",section:"Posts",handler:()=>{window.location.href="/blog/2024/PerformanceReview/"}},{id:"post-how-disruptive-ideas-were-treated",title:"How disruptive ideas were treated?",description:"of course, no one likes disruptive ideas",section:"Posts",handler:()=>{window.location.href="/blog/2023/DisruptiveIdeas/"}},{id:"post-my-reading-list",title:"My reading list",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/readinglist/"}},{id:"post-\u5173\u4e8e\u7814\u7a76\u7684\u4e00\u4e9b\u611f\u609f",title:"\u5173\u4e8e\u7814\u7a76\u7684\u4e00\u4e9b\u611f\u609f",description:"\u5e78\u8fd0\u4e4b\u795e\u4f1a\u7737\u987e\u90a3\u4e9b\u51c6\u5907\u597d\u7684\u5934\u8111\u3002",section:"Posts",handler:()=>{window.location.href="/blog/2023/onresearch/"}},{id:"news-a-heavy-metal-quartet-of-ai-compilers",title:"A \u201cheavy metal quartet\u201d of AI compilers",description:"",section:"News",handler:()=>{window.location.href="/news/heavy-metal-quartet/"}},{id:"news-unified-database-laying-the-foundation-for-large-language-model-vertical-applications",title:"Unified Database - Laying the foundation for large language model vertical applications",description:"",section:"News",handler:()=>{window.location.href="/news/vectordb/"}},{id:"news-msr-asia-startrack-scholars-program",title:"MSR-Asia StarTrack Scholars Program",description:"",section:"News",handler:()=>{window.location.href="/news/startrack2024/"}},{id:"news-internship-opportunities-at-srg",title:"Internship Opportunities at SRG",description:"",section:"News",handler:()=>{window.location.href="/news/intern_opportunities/"}},{id:"news-venturebeat-reported-rstar-math",title:"VentureBeat reported rStar-Math",description:"",section:"News",handler:()=>{window.location.href="/news/rstarmath/"}},{id:"news-an-msr-blog-introduces-our-efforts-on-low-bit-llms",title:"An MSR blog introduces our efforts on low-bit LLMs",description:"",section:"News",handler:()=>{window.location.href="/news/lowbitLLM/"}},{id:"news-an-msr-blog-introduces-our-work-on-ai-reasoning",title:"An MSR blog introduces our work on AI reasoning",description:"",section:"News",handler:()=>{window.location.href="/news/slm_reasoning/"}},{id:"news-rstar-math-and-lips-picked-as-quot-the-most-groundbreaking-ai-papers-from-the-first-half-of-2025-quot-by-turing-post",title:"rStar-Math and LIPS picked as &quot;the most groundbreaking AI papers from the first...",description:"",section:"News",handler:()=>{window.location.href="/news/rstarmathandlips/"}},{id:"news-venturebeat-covered-rstar2-agent",title:"VentureBeat covered rStar2-Agent",description:"",section:"News",handler:()=>{window.location.href="/news/rstar2-agent/"}},{id:"news-usenix-login-published-our-article-on-waferllm-osdi-39-25",title:"USENIX ;login: published our article on WaferLLM (OSDI&#39;25)",description:"",section:"News",handler:()=>{window.location.href="/news/waferllm-login/"}},{id:"news-on-a-podcast-discussing-ai-reasoning",title:"On a podcast discussing AI reasoning",description:"",section:"News",handler:()=>{window.location.href="/news/AIReasoningPodcast/"}},{id:"projects-agentic-ai",title:"Agentic AI",description:"",section:"Projects",handler:()=>{window.location.href="/projects/AgenticAI/"}},{id:"projects-ai-compiler",title:"AI compiler",description:"",section:"Projects",handler:()=>{window.location.href="/projects/aicompiler/"}},{id:"projects-ai-hardware",title:"AI hardware",description:"",section:"Projects",handler:()=>{window.location.href="/projects/aihardware/"}},{id:"projects-graph-engine",title:"Graph engine",description:"",section:"Projects",handler:()=>{window.location.href="/projects/graph/"}},{id:"projects-neuro-symbolic-ai",title:"Neuro-Symbolic AI",description:"",section:"Projects",handler:()=>{window.location.href="/projects/neuralsymbolic/"}},{id:"projects-scheduler-for-ai-workload",title:"Scheduler for AI workload",description:"",section:"Projects",handler:()=>{window.location.href="/projects/scheduling/"}},{id:"projects-vector-store",title:"Vector store",description:"",section:"Projects",handler:()=>{window.location.href="/projects/vectorstore/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>